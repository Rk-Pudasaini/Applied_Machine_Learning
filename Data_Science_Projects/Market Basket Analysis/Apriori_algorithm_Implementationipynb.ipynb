{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of Apriori Algorithms for Association Rule Mining for transations data\n",
        "\n",
        "**Here are the structured steps used in the code for the implementation of the Apriori Algorithm:**\n",
        "\n",
        "1.  Import Libraries: Import necessary libraries such as pandas for data manipulation and collections for counters.\n",
        "2.  Load Data:  Load the transactional data from a CSV file using pandas DataFrame.\n",
        "3.   Extract All Products: Define a function to extract all products from the DataFrame.\n",
        "4.   Define Global Variables: Define variables for frequent itemsets, supports, and a list to store discarded itemsets. Also, set the minimum support threshold.\n",
        "5.   Define Helper Functions:\n",
        "```\n",
        "get_items: Get unique items from the transactions.\n",
        "calculate_support: Calculate the support count of an itemset in transactions.\n",
        "print_frequent_itemsets: Print frequent itemsets and their supports.\n",
        "print_supersets: Print supersets of a given itemset.\n",
        "get_itemsetset: Generate frequent itemsets of a specified size.\n",
        "generate_frequent_itemset: Generate frequent itemsets of all sizes.\n",
        "get_subsets: Generate all possible subsets of an itemset.\n",
        "generate_association_rules: Generate association rules based on frequent itemsets.\n",
        "```\n",
        "6.   Generate Frequent Itemsets:\n",
        "```\n",
        "Get unique items from transactions.\n",
        "Iterate through all itemset sizes from 1 to the number of unique items.\n",
        "For each size, generate frequent itemsets and print them along with their supports.\n",
        "Print supersets of each frequent itemset size.\n",
        "```\n",
        "7.   Generate Association Rules:\n",
        "```\n",
        "Define the minimum confidence threshold.\n",
        "Generate association rules from the frequent itemsets.\n",
        "For each frequent itemset, generate all possible subsets.\n",
        "Calculate the confidence of each association rule.\n",
        "If the confidence meets the threshold, add the rule to the list of association rules.\n",
        "```\n",
        "8.   Print Association Rules: Print the generated association rules along with their antecedents, consequents, and confidence.\n",
        "\n",
        "This structured approach ensures the step-by-step implementation of the Apriori Algorithm for mining association rules from transactional data."
      ],
      "metadata": {
        "id": "U7IA5GD97LIa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cn4heiq3Yk1",
        "outputId": "89c52001-ae8f-4843-9070-dea381df5180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ======== n = 1 =========\n",
            "Frequent Itemsets for n=1:\n",
            "Itemset: ('shrimp',), Support: 4\n",
            "Itemset: ('avocado',), Support: 4\n",
            "Itemset: ('soup',), Support: 2\n",
            "Itemset: ('spaghetti',), Support: 7\n",
            "Itemset: ('black tea',), Support: 2\n",
            "Itemset: ('salmon',), Support: 4\n",
            "Itemset: ('green tea',), Support: 4\n",
            "Itemset: ('low fat yogurt',), Support: 3\n",
            "Itemset: ('eggs',), Support: 8\n",
            "Itemset: ('sparkling water',), Support: 2\n",
            "Itemset: ('cooking oil',), Support: 2\n",
            "Itemset: ('milk',), Support: 4\n",
            "Itemset: ('meatballs',), Support: 2\n",
            "Itemset: ('frozen smoothie',), Support: 2\n",
            "Itemset: ('burgers',), Support: 3\n",
            "Itemset: ('turkey',), Support: 4\n",
            "Itemset: ('cookies',), Support: 2\n",
            "Itemset: ('pasta',), Support: 2\n",
            "Itemset: ('chicken',), Support: 3\n",
            "Itemset: ('mineral water',), Support: 10\n",
            "Itemset: ('chocolate',), Support: 3\n",
            "Itemset: ('energy bar',), Support: 2\n",
            "Itemset: ('yams',), Support: 2\n",
            "Itemset: ('french fries',), Support: 4\n",
            "Itemset: ('honey',), Support: 4\n",
            "Itemset: ('frozen vegetables',), Support: 2\n",
            "Supersets for n=1: [{'shrimp'}, {'avocado'}, {'soup'}, {'spaghetti'}, {'black tea'}, {'salmon'}, {'green tea'}, {'low fat yogurt'}, {'eggs'}, {'sparkling water'}, {'cooking oil'}, {'milk'}, {'meatballs'}, {'frozen smoothie'}, {'burgers'}, {'turkey'}, {'cookies'}, {'pasta'}, {'chicken'}, {'mineral water'}, {'chocolate'}, {'energy bar'}, {'yams'}, {'french fries'}, {'honey'}, {'frozen vegetables'}]\n",
            " ======== n = 2 =========\n",
            "Frequent Itemsets for n=2:\n",
            "Itemset: ('shrimp', 'avocado'), Support: 2\n",
            "Itemset: ('shrimp', 'low fat yogurt'), Support: 2\n",
            "Itemset: ('shrimp', 'pasta'), Support: 2\n",
            "Itemset: ('shrimp', 'chocolate'), Support: 2\n",
            "Itemset: ('shrimp', 'honey'), Support: 3\n",
            "Itemset: ('avocado', 'honey'), Support: 2\n",
            "Itemset: ('spaghetti', 'black tea'), Support: 2\n",
            "Itemset: ('spaghetti', 'salmon'), Support: 2\n",
            "Itemset: ('spaghetti', 'green tea'), Support: 2\n",
            "Itemset: ('spaghetti', 'milk'), Support: 2\n",
            "Itemset: ('spaghetti', 'mineral water'), Support: 4\n",
            "Itemset: ('spaghetti', 'frozen vegetables'), Support: 2\n",
            "Itemset: ('black tea', 'salmon'), Support: 2\n",
            "Itemset: ('black tea', 'mineral water'), Support: 2\n",
            "Itemset: ('salmon', 'frozen smoothie'), Support: 2\n",
            "Itemset: ('salmon', 'mineral water'), Support: 4\n",
            "Itemset: ('green tea', 'mineral water'), Support: 3\n",
            "Itemset: ('low fat yogurt', 'honey'), Support: 2\n",
            "Itemset: ('eggs', 'burgers'), Support: 2\n",
            "Itemset: ('eggs', 'turkey'), Support: 3\n",
            "Itemset: ('eggs', 'chicken'), Support: 2\n",
            "Itemset: ('eggs', 'mineral water'), Support: 3\n",
            "Itemset: ('eggs', 'chocolate'), Support: 2\n",
            "Itemset: ('milk', 'mineral water'), Support: 2\n",
            "Itemset: ('milk', 'energy bar'), Support: 2\n",
            "Itemset: ('frozen smoothie', 'mineral water'), Support: 2\n",
            "Itemset: ('turkey', 'mineral water'), Support: 2\n",
            "Itemset: ('chicken', 'mineral water'), Support: 2\n",
            "Itemset: ('chicken', 'chocolate'), Support: 2\n",
            "Itemset: ('mineral water', 'energy bar'), Support: 2\n",
            "Itemset: ('mineral water', 'yams'), Support: 2\n",
            "Supersets for n=2: [{'shrimp', 'avocado'}, {'shrimp', 'low fat yogurt'}, {'shrimp', 'pasta'}, {'shrimp', 'chocolate'}, {'shrimp', 'honey'}, {'honey', 'avocado'}, {'spaghetti', 'black tea'}, {'spaghetti', 'salmon'}, {'green tea', 'spaghetti'}, {'milk', 'spaghetti'}, {'spaghetti', 'mineral water'}, {'spaghetti', 'frozen vegetables'}, {'black tea', 'salmon'}, {'black tea', 'mineral water'}, {'frozen smoothie', 'salmon'}, {'salmon', 'mineral water'}, {'green tea', 'mineral water'}, {'honey', 'low fat yogurt'}, {'burgers', 'eggs'}, {'turkey', 'eggs'}, {'chicken', 'eggs'}, {'eggs', 'mineral water'}, {'chocolate', 'eggs'}, {'milk', 'mineral water'}, {'energy bar', 'milk'}, {'frozen smoothie', 'mineral water'}, {'turkey', 'mineral water'}, {'chicken', 'mineral water'}, {'chocolate', 'chicken'}, {'energy bar', 'mineral water'}, {'yams', 'mineral water'}]\n",
            " ======== n = 3 =========\n",
            "Frequent Itemsets for n=3:\n",
            "Itemset: ('shrimp', 'avocado', 'honey'), Support: 2\n",
            "Itemset: ('shrimp', 'low fat yogurt', 'honey'), Support: 2\n",
            "Itemset: ('spaghetti', 'black tea', 'salmon'), Support: 2\n",
            "Itemset: ('spaghetti', 'black tea', 'mineral water'), Support: 2\n",
            "Itemset: ('spaghetti', 'salmon', 'mineral water'), Support: 2\n",
            "Itemset: ('black tea', 'salmon', 'mineral water'), Support: 2\n",
            "Itemset: ('salmon', 'frozen smoothie', 'mineral water'), Support: 2\n",
            "Itemset: ('eggs', 'turkey', 'mineral water'), Support: 2\n",
            "Itemset: ('eggs', 'chicken', 'mineral water'), Support: 2\n",
            "Itemset: ('milk', 'mineral water', 'energy bar'), Support: 2\n",
            "Supersets for n=3: [{'shrimp', 'honey', 'avocado'}, {'shrimp', 'honey', 'low fat yogurt'}, {'spaghetti', 'black tea', 'salmon'}, {'spaghetti', 'black tea', 'mineral water'}, {'spaghetti', 'salmon', 'mineral water'}, {'black tea', 'salmon', 'mineral water'}, {'frozen smoothie', 'salmon', 'mineral water'}, {'turkey', 'eggs', 'mineral water'}, {'chicken', 'eggs', 'mineral water'}, {'energy bar', 'milk', 'mineral water'}]\n",
            " ======== n = 4 =========\n",
            "Frequent Itemsets for n=4:\n",
            "Itemset: ('spaghetti', 'black tea', 'salmon', 'mineral water'), Support: 2\n",
            "Supersets for n=4: [{'spaghetti', 'black tea'}, {'spaghetti', 'salmon'}, {'spaghetti', 'mineral water'}, {'black tea', 'salmon'}, {'black tea', 'mineral water'}, {'salmon', 'mineral water'}, {'spaghetti', 'black tea', 'salmon', 'mineral water'}]\n",
            "Number of association rules generated: 14\n",
            "Association Rules:\n",
            "Antecedent: frozenset({'spaghetti'}) => Consequent: frozenset({'black tea', 'salmon', 'mineral water'}) | Confidence: 0.29\n",
            "Antecedent: frozenset({'black tea'}) => Consequent: frozenset({'spaghetti', 'salmon', 'mineral water'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'salmon'}) => Consequent: frozenset({'spaghetti', 'black tea', 'mineral water'}) | Confidence: 0.50\n",
            "Antecedent: frozenset({'mineral water'}) => Consequent: frozenset({'spaghetti', 'black tea', 'salmon'}) | Confidence: 0.20\n",
            "Antecedent: frozenset({'spaghetti', 'black tea'}) => Consequent: frozenset({'salmon', 'mineral water'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'spaghetti', 'salmon'}) => Consequent: frozenset({'black tea', 'mineral water'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'spaghetti', 'mineral water'}) => Consequent: frozenset({'black tea', 'salmon'}) | Confidence: 0.50\n",
            "Antecedent: frozenset({'black tea', 'salmon'}) => Consequent: frozenset({'spaghetti', 'mineral water'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'black tea', 'mineral water'}) => Consequent: frozenset({'spaghetti', 'salmon'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'salmon', 'mineral water'}) => Consequent: frozenset({'spaghetti', 'black tea'}) | Confidence: 0.50\n",
            "Antecedent: frozenset({'spaghetti', 'black tea', 'salmon'}) => Consequent: frozenset({'mineral water'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'spaghetti', 'black tea', 'mineral water'}) => Consequent: frozenset({'salmon'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'spaghetti', 'salmon', 'mineral water'}) => Consequent: frozenset({'black tea'}) | Confidence: 1.00\n",
            "Antecedent: frozenset({'black tea', 'salmon', 'mineral water'}) => Consequent: frozenset({'spaghetti'}) | Confidence: 1.00\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from itertools import combinations\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Rk-Pudasaini/Applied_Machine_Learning/main/Data_Science_Projects/Data_mining/basket_data.csv'\n",
        "df = pd.read_csv(url, header=None)\n",
        "\n",
        "# Define the function to extract all products from the DataFrame\n",
        "def extract_all_products(df):\n",
        "    all_products = []\n",
        "    for index, row in df.iterrows():\n",
        "        row_products = []\n",
        "        for cell in row:\n",
        "            if pd.notnull(cell):\n",
        "                cell_products = cell.split(',')\n",
        "                cell_products = [product.strip() for product in cell_products if product.strip()]\n",
        "                if cell_products:\n",
        "                    row_products.extend(cell_products)\n",
        "        all_products.append(row_products)\n",
        "    return all_products\n",
        "\n",
        "# Call the function to extract products\n",
        "all_products = extract_all_products(df)\n",
        "\n",
        "# Define global variables\n",
        "frequent_itemsets = []\n",
        "supports = []\n",
        "discarded = []\n",
        "min_support = 2  # Set your minimum support threshold here\n",
        "\n",
        "# Define helper functions\n",
        "def get_items(transactions):\n",
        "    items = set()\n",
        "    for transaction in transactions:\n",
        "        items.update(transaction)\n",
        "    return list(items)\n",
        "\n",
        "def calculate_support(itemset, transactions):\n",
        "    count = 0\n",
        "    for transaction in transactions:\n",
        "        if set(itemset).issubset(transaction):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "def print_frequent_itemsets(n, itemsets, supports):\n",
        "    print(f\"Frequent Itemsets for n={n}:\")\n",
        "    for i in range(len(itemsets)):\n",
        "        print(f\"Itemset: {itemsets[i]}, Support: {supports[i]}\")\n",
        "\n",
        "def print_supersets(itemset, n):\n",
        "    subsets = [set()]\n",
        "    for i in range(1, len(itemset) + 1):\n",
        "        if n == 1:\n",
        "            superset_list = [set([x]) for x in itemset]\n",
        "        elif n == 2 and i == 2:\n",
        "            superset_list = [set(pair) for pair in combinations(itemset, 2)]\n",
        "        elif n > 2:\n",
        "            if i == 1 or i == n - 1:  # Filter single item subsets and subsets of size n-1\n",
        "                superset_list = []\n",
        "            else:\n",
        "                superset_list = [set(comb) for comb in combinations(itemset, i)]\n",
        "        else:\n",
        "            superset_list = []\n",
        "\n",
        "        subsets.extend(superset_list)\n",
        "\n",
        "    subsets = [subset for subset in subsets if subset]  # Exclude empty sets\n",
        "    return subsets\n",
        "\n",
        "def get_itemsetset(items, n):\n",
        "    frequent_sets = []\n",
        "    for itemset in combinations(items, n):\n",
        "        support_count = calculate_support(itemset, transactions)\n",
        "        if support_count >= min_support:\n",
        "            frequent_sets.append(itemset)\n",
        "            supports[n - 1].append(support_count)\n",
        "        else:\n",
        "            discarded.append(itemset)\n",
        "    return frequent_sets\n",
        "\n",
        "def generate_frequent_itemset():\n",
        "    items = get_items(transactions)\n",
        "    for n in range(1, len(items) + 1):  # Generate frequent itemsets for n=1 to len(items)\n",
        "        print(f\" ======== n = {n} =========\")\n",
        "        frequent_itemsets.append([])  # Initialize the list for frequent itemsets of size n\n",
        "        supports.append([])  # Initialize the list for supports of frequent itemsets of size n\n",
        "\n",
        "        # Generate frequent itemsets of size n\n",
        "        itemsets = get_itemsetset(items, n)\n",
        "        frequent_itemsets[n - 1] = itemsets  # Update the list of frequent itemsets\n",
        "        print_frequent_itemsets(n, itemsets, supports[n - 1])\n",
        "\n",
        "        # Generate and print supersets of frequent itemsets of size n\n",
        "        all_supersets = []\n",
        "        for itemset in itemsets:\n",
        "            subsets = print_supersets(itemset, n)\n",
        "            all_supersets.extend(subsets)\n",
        "\n",
        "        print(f\"Supersets for n={n}: {all_supersets}\")\n",
        "\n",
        "        # Check if the necessary condition is met and break the loop if it is\n",
        "        if len(itemsets) <= 1:\n",
        "            break\n",
        "\n",
        "    return frequent_itemsets\n",
        "\n",
        "def get_subsets(itemset):\n",
        "    subsets = []\n",
        "    for i in range(1, len(itemset)):\n",
        "        subsets.extend(combinations(itemset, i))\n",
        "    return subsets\n",
        "\n",
        "def generate_association_rules(frequent_itemsets, min_confidence, transactions):\n",
        "    association_rules = []\n",
        "    max_itemset_number = len(frequent_itemsets) - 1\n",
        "\n",
        "    for I in frequent_itemsets[max_itemset_number]:\n",
        "        subsets = get_subsets(I)\n",
        "        for S in subsets:\n",
        "            S = frozenset(S)  # Convert the tuple to a frozenset\n",
        "            I_S = frozenset(I) - S  # Convert the tuple to a frozenset before subtracting\n",
        "            if len(I_S) <= 0:\n",
        "                continue\n",
        "            I_support = calculate_support(I, transactions)\n",
        "            S_support = calculate_support(S, transactions)\n",
        "\n",
        "            confidence = I_support / S_support\n",
        "            if confidence >= min_confidence:\n",
        "                association_rules.append((S, I_S, confidence))\n",
        "    return association_rules\n",
        "\n",
        "# Sample transactions data (replace with your actual transactions)\n",
        "transactions = all_products[:30]\n",
        "\n",
        "# Generate frequent itemsets\n",
        "frequent_itemsets = generate_frequent_itemset()\n",
        "\n",
        "# Define the minimum confidence threshold\n",
        "min_confidence = 0.2\n",
        "\n",
        "# Generate association rules\n",
        "association_rules = generate_association_rules(frequent_itemsets, min_confidence, transactions)\n",
        "\n",
        "print(\"Number of association rules generated:\", len(association_rules))  # Debugging statement\n",
        "\n",
        "# Print the association rules\n",
        "print(\"Association Rules:\")\n",
        "for antecedent, consequent, confidence in association_rules:\n",
        "    print(f\"Antecedent: {antecedent} => Consequent: {consequent} | Confidence: {confidence:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuKhYJJmh07w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}