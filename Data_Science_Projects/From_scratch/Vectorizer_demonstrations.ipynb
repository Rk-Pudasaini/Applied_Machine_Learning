{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CountVectorizer and TfidfVectorizer\n",
        "CountVectorizer and TfidfVectorizer are both methods used for converting textual data into numerical feature vectors, which can be used as input for machine learning algorithms.\n",
        "\n",
        "```\n",
        "CountVectorizer:\n",
        "\n",
        "*   CountVectorizer converts a collection of text documents into a matrix of token counts.\n",
        "*   It works by tokenizing the documents (splitting them into individual words or terms), and then building a vocabulary of known words.\n",
        "*   It converts each document into a vector of term frequencies (counts of each word in the document).\n",
        "*   The resulting matrix is a sparse matrix where each row represents a document and each column represents a unique word in the entire corpus.\n",
        "*   CountVectorizer is simple and efficient but does not consider the relative importance of words in the documents\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "TfidfVectorizer:\n",
        "\n",
        "*   TfidfVectorizer stands for \"Term Frequency-Inverse Document Frequency Vectorizer\".\n",
        "*   It converts a collection of raw documents to a matrix of TF-IDF features.\n",
        "*   TF-IDF reflects the importance of a word in a document relative to the entire corpus.\n",
        "*   TF (Term Frequency) measures the frequency of a word in a document.\n",
        "*   IDF (Inverse Document Frequency) measures how important a word is across multiple documents. Words that occur frequently across documents\n",
        "    get a lower weight.\n",
        "*   The resulting matrix contains TF-IDF values for each word in each document.\n",
        "*   TfidfVectorizer is particularly useful when dealing with large corpora, as it helps to downweight common words occurring in many documents.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "7-QXzX-1PweK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ujEhl0HHJC2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "#sample document\n",
        "documents = [\n",
        "    \"This is first document\",\n",
        "    \"This is second document\",\n",
        "    \"this is third document\",\n",
        "    \"Finally forth\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "#fit and transform the documents using CountVectorizer\n",
        "count_matrix = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "#Get the features name\n",
        "count_features_names = count_vectorizer.get_feature_names_out()\n",
        "\n",
        "#print the count mattix into array\n",
        "print(\"The count matrix into array\")\n",
        "print(count_matrix.toarray())\n",
        "print(\"Feature names:\")\n",
        "print(count_features_names)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_3__NUzKJYP",
        "outputId": "d5453fc3-2aa4-42d0-8f5a-c41a096d4dd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The count matrix into array\n",
            "[[1 0 1 0 1 0 0 1]\n",
            " [1 0 0 0 1 1 0 1]\n",
            " [1 0 0 0 1 0 1 1]\n",
            " [0 1 0 1 0 0 0 0]]\n",
            "Feature names:\n",
            "['document' 'finally' 'first' 'forth' 'is' 'second' 'third' 'this']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert count matrix to DataFrame\n",
        "count_df = pd.DataFrame(count_matrix.toarray(), columns=count_features_names)\n",
        "\n",
        "# Print count matrix in DataFrame format\n",
        "print(\"Count Vectorizer Output (Matrix Format):\")\n",
        "print(count_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCVSsOhBN0Kt",
        "outputId": "978c70bf-a31e-44a0-e0fa-ca1f78671cd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Vectorizer Output (Matrix Format):\n",
            "   document  finally  first  forth  is  second  third  this\n",
            "0         1        0      1      0   1       0      0     1\n",
            "1         1        0      0      0   1       1      0     1\n",
            "2         1        0      0      0   1       0      1     1\n",
            "3         0        1      0      1   0       0      0     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the documents using TfidfVectorizer\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "# Get the feature names\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print TF-IDF matrix\n",
        "print(\"TF-IDF Vectorizer Output:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"Feature names:\")\n",
        "print(tfidf_feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KswH-pkPC_t",
        "outputId": "eba0479b-9f09-45db-8f04-bd680c29e25e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorizer Output:\n",
            "[[0.42817512 0.         0.67081906 0.         0.42817512 0.\n",
            "  0.         0.42817512]\n",
            " [0.42817512 0.         0.         0.         0.42817512 0.67081906\n",
            "  0.         0.42817512]\n",
            " [0.42817512 0.         0.         0.         0.42817512 0.\n",
            "  0.67081906 0.42817512]\n",
            " [0.         0.70710678 0.         0.70710678 0.         0.\n",
            "  0.         0.        ]]\n",
            "Feature names:\n",
            "['document' 'finally' 'first' 'forth' 'is' 'second' 'third' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert count matrix to DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=count_features_names)\n",
        "\n",
        "# Print count matrix in DataFrame format\n",
        "print(\"Count Vectorizer Output (Matrix Format):\")\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlwVrejSRqY6",
        "outputId": "f8cb9a5b-2785-4078-b986-d5d6b0a084ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Vectorizer Output (Matrix Format):\n",
            "   document   finally     first     forth        is    second     third  \\\n",
            "0  0.428175  0.000000  0.670819  0.000000  0.428175  0.000000  0.000000   \n",
            "1  0.428175  0.000000  0.000000  0.000000  0.428175  0.670819  0.000000   \n",
            "2  0.428175  0.000000  0.000000  0.000000  0.428175  0.000000  0.670819   \n",
            "3  0.000000  0.707107  0.000000  0.707107  0.000000  0.000000  0.000000   \n",
            "\n",
            "       this  \n",
            "0  0.428175  \n",
            "1  0.428175  \n",
            "2  0.428175  \n",
            "3  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "In conclusion, the demonstrations of CountVectorizer and TfidfVectorizer showcase two fundamental approaches to converting textual data into numerical representations for machine learning tasks. CountVectorizer efficiently transforms text documents into a matrix of token counts, providing a straightforward method for representing textual data numerically. It is well-suited for tasks where the frequency of word occurrence in documents is relevant, such as text classification and clustering.\n",
        "\n",
        "On the other hand, TfidfVectorizer offers a more nuanced representation by considering both the frequency of words in documents and their importance across the entire corpus through TF-IDF weighting. This approach enables TfidfVectorizer to downweight common words and highlight important ones, making it particularly useful for tasks where word importance in distinguishing between documents is crucial, such as information retrieval and document similarity. Overall, while CountVectorizer offers simplicity and speed, TfidfVectorizer provides a more sophisticated representation of text data, making the choice between them dependent on the specific requirements and objectives of the natural language processing task at hand."
      ],
      "metadata": {
        "id": "KJk_M0eNSvGo"
      }
    }
  ]
}